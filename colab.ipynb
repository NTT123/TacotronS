{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NTT123/TacotronS/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2JhekS77Y-2Q"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt install sox\n",
        "!pip install -Uqq unidecode pax3 opax toml fire tensorflow-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dZuSEtkCY-2U",
        "outputId": "71ffb388-9443-4bd1-ef63-0f2d3415e4a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'TacotronS'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 212 (delta 1), reused 8 (delta 1), pack-reused 204\u001b[K\n",
            "Receiving objects: 100% (212/212), 48.00 MiB | 26.21 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "/content/TacotronS\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/NTT123/TacotronS.git\n",
        "%cd /content/TacotronS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fkFZWPIhY-2V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm.cli import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fz48k38WY-2W",
        "outputId": "918cd913-fd6f-4396-d0b6-8aaa34ac001f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from 'https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2' to file '/root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2'.\n",
            "100%|█████████████████████████████████████| 2.75G/2.75G [00:00<00:00, 13.3TB/s]\n",
            "Untarring contents of '/root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2' to '/root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2.untar'\n",
            "Data is prepared in the directory '/root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2.untar/LJSpeech-1.1/wavs'.\n",
            "\n",
            "Run 'python data.py /root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2.untar/LJSpeech-1.1/wavs' to create the tensorflow dataset.\n"
          ]
        }
      ],
      "source": [
        "# download LJSpeech dataset\n",
        "!python ljs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GDDNfFW1Y-2W",
        "outputId": "da86daa2-d4f9-448a-f29a-24585e4f45c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13100/13100 [04:19<00:00, 50.49it/s]\n"
          ]
        }
      ],
      "source": [
        "# resample to 24k\n",
        "!mkdir -p wav_24k\n",
        "wav_dir = Path(\"/root/.cache/pooch/b5107092215abf6367ef755eb0633116-LJSpeech-1.1.tar.bz2.untar/LJSpeech-1.1/wavs\")\n",
        "wav_files = sorted(wav_dir.glob(\"*.wav\"))\n",
        "for path in tqdm(wav_files):\n",
        "    cmd = f\"sox {path} -c 1 --norm=-3 -r 24000 wav_24k/{path.name}\"\n",
        "    os.system(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OXDiYAs6Y-2X"
      },
      "outputs": [],
      "source": [
        "!cp {wav_dir}/*.txt ./wav_24k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3yJfw8ocY-2X",
        "outputId": "2fe8ba41-6605-483b-b59d-61326013289e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from directory 'wav_24k'\n",
            "100% 13100/13100 [00:00<00:00, 15091.60it/s]\n",
            "100% 13100/13100 [03:42<00:00, 58.85it/s] \n",
            "Created a tensorflow dataset at 'tf_data'.\n",
            "\n",
            "Run 'python train.py' to train your model.\n"
          ]
        }
      ],
      "source": [
        "# create tf dataset\n",
        "!python data.py wav_24k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nqccXZL_Y-2Y"
      },
      "outputs": [],
      "source": [
        "# uncomment to save checkpoints to google drive\n",
        "# !mkdir /content/drive/MyDrive/{logs,ckpts}\n",
        "# !ln -sfT /content/drive/MyDrive/ckpts ./ckpts\n",
        "# !ln -sfT /content/drive/MyDrive/logs ./logs\n",
        "!mkdir -p ckpts logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8UVJH0sY-2Z",
        "outputId": "8b90acc1-a785-44e2-f25c-3cd397aa22ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-25 11:22:59.032696: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
            "Devices: [GpuDevice(id=0, process_index=0)]\n",
            "step 0000000  loss 0.269  LR 1.024e-03  41.03s\n",
            "step 0000100  loss 1.137  LR 1.024e-03  94.76s\n",
            "step 0000200  loss 0.871  LR 1.024e-03  88.59s\n",
            "step 0000300  loss 0.802  LR 1.024e-03  88.53s\n",
            "step 0000400  loss 0.766  LR 1.024e-03  88.73s\n",
            "step 0000500  loss 0.741  LR 1.024e-03  88.48s\n",
            "step 0000600  loss 0.718  LR 1.024e-03  88.53s\n",
            "step 0000700  loss 0.698  LR 1.024e-03  88.58s\n",
            "step 0000800  loss 0.686  LR 1.024e-03  88.51s\n",
            "step 0000900  loss 0.668  LR 1.024e-03  88.46s\n",
            "step 0001000  loss 0.657  LR 1.024e-03  88.49s\n"
          ]
        }
      ],
      "source": [
        "# Use reduction factor of 2 for robust attention learning\n",
        "!RR=2 TRAINING_STEPS=50000 python train.py --batch-size=64 | tee -a ./logs/training_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --batch-size=32 | tee -a ./logs/training_logs.txt"
      ],
      "metadata": {
        "id": "9IXXU65UdaE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "1b63408a06afa1ceea6203a9761e579688f17d9bfdae85f0214f682761b70f46"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}